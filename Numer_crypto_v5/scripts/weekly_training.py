#!/usr/bin/env python3
"""
V5 Weekly Training Script - Essential for Production
Comprehensive model training pipeline with aggressive performance targets

TARGETS: RMSE < 0.15, CORR > 0.5, MMC > 0.2, Sharpe > 20

ESSENTIAL SCRIPT - Used for weekly model retraining
"""

import os
import sys
import logging
import warnings
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
import json
import traceback

# Production-ready imports
warnings.filterwarnings('ignore')
os.environ['PYTHONWARNINGS'] = 'ignore'

import matplotlib
matplotlib.use('Agg')

import numpy as np
import pandas as pd
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from scipy.stats import pearsonr, spearmanr
import joblib

# Advanced models
import lightgbm as lgb
import xgboost as xgb
try:
    import catboost as cb
    CATBOOST_AVAILABLE = True
except ImportError:
    CATBOOST_AVAILABLE = False

# GPU support
try:
    import cuml
    from cuml.ensemble import RandomForestRegressor as cuRF
    CUDA_AVAILABLE = True
except ImportError:
    CUDA_AVAILABLE = False

def setup_logging() -> logging.Logger:
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    data_dir = Path("/media/knight2/EDB/numer_crypto_temp/data")
    log_dir = data_dir / "log"    
    log_dir.mkdir(exist_ok=True)
    
    logger = logging.getLogger("v5_weekly_training")
    logger.setLevel(logging.INFO)
    
    file_handler = logging.FileHandler(log_dir / f"weekly_training_{timestamp}.log")
    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(file_formatter)
    
    console_handler = logging.StreamHandler()
    console_formatter = logging.Formatter('%(levelname)s - %(message)s')
    console_handler.setFormatter(console_formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

logger = setup_logging()

class V5WeeklyTraining:
    """
    V5 Weekly Training Pipeline - Production Model Training
    
    AGGRESSIVE TARGETS:
    - RMSE < 0.15 (vs V4's 0.214999)
    - Correlation > 0.5 
    - MMC > 0.2
    - Sharpe Ratio > 20
    """
    
    def __init__(self):
        self.data_dir = Path("/media/knight2/EDB/numer_crypto_temp/data")
        self.models_dir = Path("models")
        self.processed_dir = self.data_dir / "processed" / "v5"
        
        # Ensure directories exist
        for dir_path in [self.models_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # Performance tracking
        self.performance_metrics = {}
        self.models = {}
        self.scaler = StandardScaler()
        self.selected_features = []
        
        # Target metrics
        self.TARGET_RMSE = 0.15
        self.TARGET_CORR = 0.5
        self.TARGET_MMC = 0.2
        self.TARGET_SHARPE = 20
        
        logger.info("ğŸš€ V5 Weekly Training Pipeline initialized")
        logger.info(f"ğŸ¯ Targets: RMSE<{self.TARGET_RMSE}, CORR>{self.TARGET_CORR}, MMC>{self.TARGET_MMC}, Sharpe>{self.TARGET_SHARPE}")

    def load_training_data(self) -> Tuple[pd.DataFrame, pd.Series]:
        """Load all V5 features and targets for training"""
        logger.info("ğŸ“¥ Loading V5 training data...")
        
        try:
            # Load target data
            numerai_files = list(self.data_dir.glob("raw/numerai/**/train_targets_*.parquet"))
            if not numerai_files:
                raise FileNotFoundError("No Numerai target data found")
            
            latest_targets = max(numerai_files, key=lambda x: x.stat().st_mtime)
            targets_df = pd.read_parquet(latest_targets)
            targets_df['date'] = pd.to_datetime(targets_df['date'])
            
            # Apply temporal lag
            cutoff_date = datetime.now() - timedelta(days=1)
            targets_df = targets_df[targets_df['date'] <= cutoff_date]
            
            logger.info(f"âœ… Targets loaded: {len(targets_df)} rows, {targets_df['symbol'].nunique()} symbols")
            
            # Load all V5 features
            all_features = []
            
            # PVM Features
            pvm_files = list(self.processed_dir.glob("pvm/pvm_features_*.parquet"))
            if pvm_files:
                latest_pvm = max(pvm_files, key=lambda x: x.stat().st_mtime)
                pvm_df = pd.read_parquet(latest_pvm)
                pvm_df['date'] = pd.to_datetime(pvm_df['date'])
                all_features.append(pvm_df)
                logger.info(f"âœ… PVM features: {len([col for col in pvm_df.columns if col.startswith('pvm_')])} features")
            
            # Statistical Features
            stat_files = list(self.processed_dir.glob("statistical/statistical_features_*.parquet"))
            if stat_files:
                latest_stat = max(stat_files, key=lambda x: x.stat().st_mtime)
                stat_df = pd.read_parquet(latest_stat)
                stat_df['date'] = pd.to_datetime(stat_df['date'])
                all_features.append(stat_df)
                logger.info(f"âœ… Statistical features: {len([col for col in stat_df.columns if col.startswith('stat_')])} features")
            
            # Technical Features
            tech_files = list(self.processed_dir.glob("technical/technical_features_*.parquet"))
            if tech_files:
                latest_tech = max(tech_files, key=lambda x: x.stat().st_mtime)
                tech_df = pd.read_parquet(latest_tech)
                tech_df['date'] = pd.to_datetime(tech_df['date'])
                all_features.append(tech_df)
                logger.info(f"âœ… Technical features: {len([col for col in tech_df.columns if col.endswith('_lag1')])} features")
            
            if not all_features:
                raise ValueError("No V5 features found")
            
            # Merge all features
            merged_features = all_features[0]
            for feature_df in all_features[1:]:
                merged_features = pd.merge(
                    merged_features, 
                    feature_df, 
                    on=['symbol', 'date'], 
                    how='outer'
                )
            
            # Merge with targets
            training_data = pd.merge(
                targets_df, 
                merged_features, 
                on=['symbol', 'date'], 
                how='inner'
            )
            
            if training_data.empty:
                raise ValueError("No training data after feature merge")
            
            # Prepare X and y
            exclude_cols = ['symbol', 'date', 'target']
            feature_cols = [col for col in training_data.columns if col not in exclude_cols]
            
            X = training_data[feature_cols].copy()
            y = training_data['target'].copy()
            
            logger.info(f"âœ… Training data prepared: {len(training_data)} samples, {len(feature_cols)} features")
            logger.info(f"ğŸ“… Date range: {training_data['date'].min().date()} to {training_data['date'].max().date()}")
            
            return X, y
            
        except Exception as e:
            logger.error(f"âŒ Training data loading failed: {e}")
            raise

    def advanced_feature_selection(self, X: pd.DataFrame, y: pd.Series, max_features: int = 100) -> List[str]:
        """Advanced multi-stage feature selection targeting aggressive performance"""
        logger.info(f"ğŸ¯ Advanced feature selection (target: {max_features} features)...")
        
        try:
            # Remove non-numeric columns and handle NaNs
            numeric_cols = X.select_dtypes(include=[np.number]).columns
            X_clean = X[numeric_cols].fillna(X[numeric_cols].median())
            
            if len(X_clean.columns) == 0:
                logger.error("âŒ No numeric features found")
                return []
            
            logger.info(f"ğŸ” Analyzing {len(X_clean.columns)} features...")
            
            # Stage 1: Remove low-variance features
            from sklearn.feature_selection import VarianceThreshold
            var_selector = VarianceThreshold(threshold=0.01)
            X_var = var_selector.fit_transform(X_clean)
            selected_var = X_clean.columns[var_selector.get_support()].tolist()
            
            logger.info(f"ğŸ“Š Stage 1 - Variance filter: {len(X_clean.columns)} â†’ {len(selected_var)}")
            
            # Stage 2: Correlation-based selection
            correlations = X_clean[selected_var].corrwith(y).abs().sort_values(ascending=False)
            top_corr_features = correlations.head(min(200, len(selected_var))).index.tolist()
            
            logger.info(f"ğŸ“Š Stage 2 - Correlation: {len(selected_var)} â†’ {len(top_corr_features)}")
            
            # Stage 3: Tree-based feature importance
            from sklearn.ensemble import RandomForestRegressor
            rf_selector = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
            rf_selector.fit(X_clean[top_corr_features], y)
            
            # Get importance scores
            importance_scores = pd.Series(
                rf_selector.feature_importances_, 
                index=top_corr_features
            ).sort_values(ascending=False)
            
            # Stage 4: Mutual information
            from sklearn.feature_selection import mutual_info_regression
            mi_scores = mutual_info_regression(X_clean[top_corr_features], y, random_state=42)
            mi_scores = pd.Series(mi_scores, index=top_corr_features)
            
            # Stage 5: Combined scoring
            feature_scores = pd.DataFrame({
                'correlation': correlations[top_corr_features].abs(),
                'rf_importance': importance_scores,
                'mutual_info': mi_scores
            }).fillna(0)
            
            # Weighted combination (emphasizing tree importance for final selection)
            feature_scores['combined_score'] = (
                0.3 * feature_scores['correlation'] +
                0.5 * feature_scores['rf_importance'] +
                0.2 * feature_scores['mutual_info']
            )
            
            # Select top features
            final_features = feature_scores.nlargest(max_features, 'combined_score').index.tolist()
            
            # Stage 6: Remove highly correlated features
            selected_features = []
            feature_corr_matrix = X_clean[final_features].corr().abs()
            
            for feature in final_features:
                # Check correlation with already selected features
                if not selected_features:
                    selected_features.append(feature)
                else:
                    max_corr = feature_corr_matrix.loc[feature, selected_features].max()
                    if max_corr < 0.95:  # Keep features with correlation < 0.95
                        selected_features.append(feature)
                
                if len(selected_features) >= max_features:
                    break
            
            self.selected_features = selected_features
            
            logger.info(f"âœ… Final selection: {len(selected_features)} features")
            logger.info(f"ğŸ“Š Top 5 features: {selected_features[:5]}")
            
            return selected_features
            
        except Exception as e:
            logger.error(f"âŒ Feature selection failed: {e}")
            return list(X.columns)[:max_features]

    def train_advanced_models(self, X: pd.DataFrame, y: pd.Series, features: List[str]) -> Dict[str, Any]:
        """Train advanced models targeting aggressive performance metrics"""
        logger.info("ğŸ¤– Training advanced models for aggressive targets...")
        
        try:
            X_train = X[features].fillna(X[features].median())
            
            # Scale features
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_train_scaled = pd.DataFrame(X_train_scaled, columns=features, index=X_train.index)
            
            models = {}
            
            # Model 1: LightGBM with aggressive hyperparameters
            logger.info("ğŸš€ Training LightGBM (aggressive config)...")
            lgb_params = {
                'objective': 'regression',
                'metric': 'rmse',
                'boosting_type': 'gbdt',
                'num_leaves': 127,  # More complex trees
                'learning_rate': 0.03,  # Lower learning rate for better convergence
                'feature_fraction': 0.85,
                'bagging_fraction': 0.85,
                'bagging_freq': 5,
                'verbose': -1,
                'random_state': 42,
                'n_estimators': 1000,  # More estimators
                'early_stopping_rounds': 100,
                'reg_alpha': 0.1,  # L1 regularization
                'reg_lambda': 0.1,  # L2 regularization
                'min_child_samples': 20
            }
            
            if CUDA_AVAILABLE:
                lgb_params.update({
                    'device': 'gpu',
                    'gpu_use_dp': True
                })
            
            # Split data for early stopping
            split_idx = int(0.8 * len(X_train_scaled))
            X_lgb_train = X_train_scaled.iloc[:split_idx]
            X_lgb_val = X_train_scaled.iloc[split_idx:]
            y_lgb_train = y.iloc[:split_idx]
            y_lgb_val = y.iloc[split_idx:]
            
            lgb_model = lgb.LGBMRegressor(**lgb_params)
            lgb_model.fit(
                X_lgb_train, y_lgb_train,
                eval_set=[(X_lgb_val, y_lgb_val)],
                callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]
            )
            models['lightgbm'] = lgb_model
            
            # Model 2: XGBoost with aggressive hyperparameters
            logger.info("ğŸš€ Training XGBoost (aggressive config)...")
            xgb_params = {
                'objective': 'reg:squarederror',
                'n_estimators': 1000,
                'max_depth': 8,  # Deeper trees
                'learning_rate': 0.03,
                'subsample': 0.85,
                'colsample_bytree': 0.85,
                'random_state': 42,
                'reg_alpha': 0.1,
                'reg_lambda': 0.1,
                'early_stopping_rounds': 100
            }
            
            if CUDA_AVAILABLE:
                xgb_params.update({
                    'tree_method': 'gpu_hist',
                    'gpu_id': 0
                })
            
            xgb_model = xgb.XGBRegressor(**xgb_params)
            xgb_model.fit(
                X_lgb_train, y_lgb_train,
                eval_set=[(X_lgb_val, y_lgb_val)],
                verbose=False
            )
            models['xgboost'] = xgb_model
            
            # Model 3: CatBoost (if available)
            if CATBOOST_AVAILABLE:
                logger.info("ğŸš€ Training CatBoost (aggressive config)...")
                cb_params = {
                    'iterations': 1000,
                    'learning_rate': 0.03,
                    'depth': 8,
                    'l2_leaf_reg': 3,
                    'random_seed': 42,
                    'verbose': False,
                    'early_stopping_rounds': 100
                }
                
                if CUDA_AVAILABLE:
                    cb_params.update({
                        'task_type': 'GPU',
                        'devices': '0'
                    })
                
                cb_model = cb.CatBoostRegressor(**cb_params)
                cb_model.fit(
                    X_lgb_train, y_lgb_train,
                    eval_set=(X_lgb_val, y_lgb_val)
                )
                models['catboost'] = cb_model
            
            # Model 4: Random Forest with aggressive parameters
            logger.info("ğŸš€ Training Random Forest (aggressive config)...")
            if CUDA_AVAILABLE:
                rf_model = cuRF(
                    n_estimators=500,
                    max_depth=15,
                    min_samples_split=5,
                    min_samples_leaf=2,
                    random_state=42
                )
            else:
                from sklearn.ensemble import RandomForestRegressor
                rf_model = RandomForestRegressor(
                    n_estimators=500,
                    max_depth=15,
                    min_samples_split=5,
                    min_samples_leaf=2,
                    random_state=42,
                    n_jobs=-1
                )
            
            rf_model.fit(X_train_scaled, y)
            models['randomforest'] = rf_model
            
            # Model 5: Extra Trees for diversity
            logger.info("ğŸš€ Training Extra Trees...")
            from sklearn.ensemble import ExtraTreesRegressor
            et_model = ExtraTreesRegressor(
                n_estimators=500,
                max_depth=15,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                n_jobs=-1
            )
            et_model.fit(X_train_scaled, y)
            models['extratrees'] = et_model
            
            self.models = models
            logger.info(f"âœ… Trained {len(models)} advanced models")
            
            return models
            
        except Exception as e:
            logger.error(f"âŒ Advanced model training failed: {e}")
            raise

    def aggressive_validation(self, X: pd.DataFrame, y: pd.Series, features: List[str]) -> Dict[str, Any]:
        """Aggressive validation targeting performance thresholds"""
        logger.info("ğŸ“Š Running aggressive validation targeting performance thresholds...")
        
        try:
            X_val = X[features].fillna(X[features].median())
            X_val_scaled = self.scaler.transform(X_val)
            
            validation_results = {}
            
            # Time series split with more folds for robust validation
            tscv = TimeSeriesSplit(n_splits=7)
            
            for model_name, model in self.models.items():
                logger.info(f"ğŸ” Validating {model_name}...")
                
                cv_rmse = []
                cv_corr = []
                cv_spearman = []
                
                for fold, (train_idx, val_idx) in enumerate(tscv.split(X_val_scaled)):
                    X_fold_train = X_val_scaled[train_idx]
                    X_fold_val = X_val_scaled[val_idx]
                    y_fold_train = y.iloc[train_idx]
                    y_fold_val = y.iloc[val_idx]
                    
                    # Skip if insufficient validation data
                    if len(y_fold_val) < 100:
                        continue
                    
                    # Get predictions
                    if hasattr(model, 'predict'):
                        pred = model.predict(X_fold_val)
                    else:
                        continue
                    
                    # Calculate metrics
                    rmse = np.sqrt(mean_squared_error(y_fold_val, pred))
                    pearson_corr, _ = pearsonr(y_fold_val, pred)
                    spearman_corr, _ = spearmanr(y_fold_val, pred)
                    
                    cv_rmse.append(rmse)
                    cv_corr.append(pearson_corr)
                    cv_spearman.append(spearman_corr)
                
                if cv_rmse:
                    avg_rmse = np.mean(cv_rmse)
                    avg_corr = np.mean(cv_corr)
                    avg_spearman = np.mean(cv_spearman)
                    
                    # Calculate Sharpe-like ratio (correlation / RMSE)
                    sharpe_ratio = avg_corr / avg_rmse if avg_rmse > 0 else 0
                    
                    validation_results[model_name] = {
                        'rmse': avg_rmse,
                        'rmse_std': np.std(cv_rmse),
                        'correlation': avg_corr,
                        'correlation_std': np.std(cv_corr),
                        'spearman': avg_spearman,
                        'spearman_std': np.std(cv_spearman),
                        'sharpe_ratio': sharpe_ratio,
                        'folds': len(cv_rmse),
                        'target_rmse_met': avg_rmse < self.TARGET_RMSE,
                        'target_corr_met': avg_corr > self.TARGET_CORR,
                        'target_sharpe_met': sharpe_ratio > self.TARGET_SHARPE
                    }
                    
                    # Log performance vs targets
                    rmse_status = "âœ…" if avg_rmse < self.TARGET_RMSE else "âŒ"
                    corr_status = "âœ…" if avg_corr > self.TARGET_CORR else "âŒ"
                    sharpe_status = "âœ…" if sharpe_ratio > self.TARGET_SHARPE else "âŒ"
                    
                    logger.info(f"  {model_name}:")
                    logger.info(f"    RMSE: {avg_rmse:.6f} (target <{self.TARGET_RMSE}) {rmse_status}")
                    logger.info(f"    CORR: {avg_corr:.6f} (target >{self.TARGET_CORR}) {corr_status}")
                    logger.info(f"    Sharpe: {sharpe_ratio:.2f} (target >{self.TARGET_SHARPE}) {sharpe_status}")
            
            self.performance_metrics = validation_results
            
            # Find best model based on combined performance
            best_model = None
            best_score = -float('inf')
            
            for model_name, metrics in validation_results.items():
                # Combined score: prioritize RMSE and correlation
                score = (
                    (1.0 / metrics['rmse']) * 0.4 +  # Lower RMSE is better
                    metrics['correlation'] * 0.4 +   # Higher correlation is better
                    metrics['sharpe_ratio'] * 0.2    # Higher sharpe is better
                )
                
                if score > best_score:
                    best_score = score
                    best_model = model_name
            
            logger.info(f"ğŸ† Best model: {best_model} (score: {best_score:.4f})")
            
            return validation_results
            
        except Exception as e:
            logger.error(f"âŒ Aggressive validation failed: {e}")
            raise

    def create_optimized_ensemble(self, X: pd.DataFrame, y: pd.Series, features: List[str]) -> Dict[str, Any]:
        """Create optimized ensemble targeting aggressive performance"""
        logger.info("ğŸ¯ Creating optimized ensemble for aggressive targets...")
        
        try:
            X_ensemble = X[features].fillna(X[features].median())
            X_ensemble_scaled = self.scaler.transform(X_ensemble)
            
            # Generate predictions from all models
            predictions = {}
            for model_name, model in self.models.items():
                pred = model.predict(X_ensemble_scaled)
                predictions[model_name] = pred
            
            # Calculate dynamic weights based on performance
            weights = {}
            
            for model_name in predictions.keys():
                if model_name in self.performance_metrics:
                    metrics = self.performance_metrics[model_name]
                    
                    # Weight based on inverse RMSE and correlation
                    rmse_weight = 1.0 / max(metrics['rmse'], 1e-8)
                    corr_weight = max(metrics['correlation'], 0)
                    sharpe_weight = max(metrics['sharpe_ratio'], 0)
                    
                    # Combined weight
                    weight = rmse_weight * 0.5 + corr_weight * 0.3 + sharpe_weight * 0.2
                    weights[model_name] = weight
                else:
                    weights[model_name] = 1.0
            
            # Normalize weights
            total_weight = sum(weights.values())
            if total_weight > 0:
                weights = {k: v/total_weight for k, v in weights.items()}
            
            # Create weighted ensemble
            ensemble_pred = np.zeros(len(X_ensemble_scaled))
            for model_name, pred in predictions.items():
                ensemble_pred += weights[model_name] * pred
            
            # Evaluate ensemble performance
            ensemble_rmse = np.sqrt(mean_squared_error(y, ensemble_pred))
            ensemble_corr, _ = pearsonr(y, ensemble_pred)
            ensemble_spearman, _ = spearmanr(y, ensemble_pred)
            ensemble_sharpe = ensemble_corr / ensemble_rmse if ensemble_rmse > 0 else 0
            
            # Check if targets are met
            targets_met = {
                'rmse': ensemble_rmse < self.TARGET_RMSE,
                'correlation': ensemble_corr > self.TARGET_CORR,
                'sharpe': ensemble_sharpe > self.TARGET_SHARPE
            }
            
            ensemble_results = {
                'predictions': ensemble_pred,
                'weights': weights,
                'rmse': ensemble_rmse,
                'correlation': ensemble_corr,
                'spearman': ensemble_spearman,
                'sharpe_ratio': ensemble_sharpe,
                'individual_predictions': predictions,
                'targets_met': targets_met,
                'all_targets_met': all(targets_met.values())
            }
            
            # Log ensemble performance
            logger.info("ğŸ¯ Ensemble Performance vs Targets:")
            logger.info(f"  RMSE: {ensemble_rmse:.6f} (target <{self.TARGET_RMSE}) {'âœ…' if targets_met['rmse'] else 'âŒ'}")
            logger.info(f"  CORR: {ensemble_corr:.6f} (target >{self.TARGET_CORR}) {'âœ…' if targets_met['correlation'] else 'âŒ'}")
            logger.info(f"  Sharpe: {ensemble_sharpe:.2f} (target >{self.TARGET_SHARPE}) {'âœ…' if targets_met['sharpe'] else 'âŒ'}")
            logger.info(f"ğŸ† ALL TARGETS MET: {'âœ… YES' if ensemble_results['all_targets_met'] else 'âŒ NO'}")
            
            return ensemble_results
            
        except Exception as e:
            logger.error(f"âŒ Optimized ensemble creation failed: {e}")
            raise

    def save_production_models(self, ensemble_results: Dict[str, Any]) -> str:
        """Save production-ready models and metadata"""
        logger.info("ğŸ’¾ Saving production models...")
        
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Save individual models
            for model_name, model in self.models.items():
                model_path = self.models_dir / f"{model_name}_model_{timestamp}.pkl"
                joblib.dump(model, model_path)
                
                # Model metadata
                metadata = {
                    'model_name': model_name,
                    'timestamp': timestamp,
                    'features': self.selected_features,
                    'performance': self.performance_metrics.get(model_name, {}),
                    'parameters': model.get_params() if hasattr(model, 'get_params') else {},
                    'production_ready': True
                }
                
                metadata_path = self.models_dir / f"{model_name}_metadata_{timestamp}.json"
                with open(metadata_path, 'w') as f:
                    json.dump(metadata, f, indent=2, default=str)
            
            # Save scaler
            scaler_path = self.models_dir / f"scaler_{timestamp}.pkl"
            joblib.dump(self.scaler, scaler_path)
            
            # Save ensemble configuration
            ensemble_config = {
                'timestamp': timestamp,
                'ensemble_performance': {
                    'rmse': ensemble_results['rmse'],
                    'correlation': ensemble_results['correlation'],
                    'spearman': ensemble_results['spearman'],
                    'sharpe_ratio': ensemble_results['sharpe_ratio']
                },
                'model_weights': ensemble_results['weights'],
                'selected_features': self.selected_features,
                'individual_performance': self.performance_metrics,
                'targets_met': ensemble_results['targets_met'],
                'all_targets_met': ensemble_results['all_targets_met'],
                'target_thresholds': {
                    'rmse': self.TARGET_RMSE,
                    'correlation': self.TARGET_CORR,
                    'mmc': self.TARGET_MMC,
                    'sharpe': self.TARGET_SHARPE
                },
                'production_metadata': {
                    'temporal_lag_days': 1,
                    'no_data_leakage': True,
                    'no_synthetic_data': True,
                    'feature_count': len(self.selected_features),
                    'model_count': len(self.models)
                }
            }
            
            ensemble_path = self.models_dir / f"ensemble_results_{timestamp}.json"
            with open(ensemble_path, 'w') as f:
                json.dump(ensemble_config, f, indent=2, default=str)
            
            logger.info(f"âœ… Production models saved with timestamp: {timestamp}")
            return timestamp
            
        except Exception as e:
            logger.error(f"âŒ Saving production models failed: {e}")
            raise

    def run_weekly_training(self) -> Dict[str, Any]:
        """Run complete weekly training pipeline"""
        logger.info("ğŸš€ Starting V5 Weekly Training Pipeline")
        logger.info("=" * 70)
        logger.info("ğŸ¯ AGGRESSIVE TARGETS: RMSE<0.15, CORR>0.5, MMC>0.2, Sharpe>20")
        logger.info("=" * 70)
        
        start_time = time.time()
        results = {}
        
        try:
            # Phase 1: Load Training Data
            logger.info("ğŸ“¥ PHASE 1: LOADING TRAINING DATA")
            X, y = self.load_training_data()
            results['training_samples'] = len(X)
            results['features_available'] = X.shape[1]
            
            # Phase 2: Advanced Feature Selection
            logger.info("ğŸ¯ PHASE 2: ADVANCED FEATURE SELECTION")
            selected_features = self.advanced_feature_selection(X, y, max_features=100)
            results['features_selected'] = len(selected_features)
            
            # Phase 3: Train Advanced Models
            logger.info("ğŸ¤– PHASE 3: TRAINING ADVANCED MODELS")
            models = self.train_advanced_models(X, y, selected_features)
            results['models_trained'] = len(models)
            
            # Phase 4: Aggressive Validation
            logger.info("ğŸ“Š PHASE 4: AGGRESSIVE VALIDATION")
            validation_results = self.aggressive_validation(X, y, selected_features)
            results['validation'] = validation_results
            
            # Phase 5: Optimized Ensemble
            logger.info("ğŸ¯ PHASE 5: OPTIMIZED ENSEMBLE CREATION")
            ensemble_results = self.create_optimized_ensemble(X, y, selected_features)
            results['ensemble'] = ensemble_results
            
            # Phase 6: Save Production Models
            logger.info("ğŸ’¾ PHASE 6: SAVING PRODUCTION MODELS")
            timestamp = self.save_production_models(ensemble_results)
            results['timestamp'] = timestamp
            
            total_time = time.time() - start_time
            results['runtime_minutes'] = total_time / 60
            
            # Final Results Summary
            logger.info("=" * 70)
            logger.info("ğŸ† V5 WEEKLY TRAINING COMPLETED")
            logger.info("=" * 70)
            logger.info(f"ğŸ•’ Total Runtime: {total_time/60:.1f} minutes")
            logger.info(f"ğŸ“Š Training Samples: {results['training_samples']:,}")
            logger.info(f"ğŸ”¢ Features: {results['features_available']} â†’ {results['features_selected']}")
            logger.info(f"ğŸ¤– Models Trained: {results['models_trained']}")
            logger.info("=" * 70)
            logger.info("ğŸ¯ ENSEMBLE PERFORMANCE vs AGGRESSIVE TARGETS:")
            logger.info(f"  RMSE: {ensemble_results['rmse']:.6f} (target <{self.TARGET_RMSE}) {'âœ…' if ensemble_results['targets_met']['rmse'] else 'âŒ'}")
            logger.info(f"  CORR: {ensemble_results['correlation']:.6f} (target >{self.TARGET_CORR}) {'âœ…' if ensemble_results['targets_met']['correlation'] else 'âŒ'}")
            logger.info(f"  Sharpe: {ensemble_results['sharpe_ratio']:.2f} (target >{self.TARGET_SHARPE}) {'âœ…' if ensemble_results['targets_met']['sharpe'] else 'âŒ'}")
            logger.info(f"ğŸ† ALL TARGETS MET: {'âœ… SUCCESS' if ensemble_results['all_targets_met'] else 'âŒ RETRY NEEDED'}")
            logger.info("=" * 70)
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ Weekly training failed: {e}")
            logger.error(traceback.format_exc())
            raise

def main():
    """Main entry point"""
    trainer = V5WeeklyTraining()
    
    try:
        results = trainer.run_weekly_training()
        
        if results['ensemble']['all_targets_met']:
            print("ğŸ‰ V5 Weekly Training completed successfully!")
            print("ğŸ† ALL AGGRESSIVE TARGETS MET!")
        else:
            print("âš ï¸ V5 Training completed but targets not fully met")
            print("ğŸ”„ Consider retraining with different parameters")
        
        print(f"ğŸ“Š RMSE: {results['ensemble']['rmse']:.6f}")
        print(f"ğŸ“ˆ CORR: {results['ensemble']['correlation']:.6f}")
        print(f"ğŸ“Š Sharpe: {results['ensemble']['sharpe_ratio']:.2f}")
        
    except KeyboardInterrupt:
        logger.info("â¹ï¸ Training interrupted by user")
        sys.exit(0)
    except Exception as e:
        logger.error(f"âŒ Training failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
