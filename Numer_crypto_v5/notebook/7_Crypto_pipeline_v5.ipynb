{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "crypto-pipeline-title",
   "metadata": {},
   "source": [
    "# üèÜ CRYPTO PIPELINE V5 - STREAMLINED NOTEBOOK\n",
    "## Numerai Cryptocurrency Prediction with Selected Models\n",
    "\n",
    "**Features:**\n",
    "- H2O AutoML with Sparkling Water\n",
    "- AutoGluon TimeSeries for temporal predictions\n",
    "- SynapseML LightGBM with advanced hyperparameters\n",
    "- GPU acceleration and comprehensive feature engineering\n",
    "- Real-time submission file generation\n",
    "\n",
    "**Performance Targets:**\n",
    "- RMSE < 0.19\n",
    "- Correlation > 0.50\n",
    "- MMC > 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup-environment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment configured for dual GPU processing\n"
     ]
    }
   ],
   "source": [
    "# Environment setup\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU Configuration for maximum performance\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "os.environ['CUPY_GPU_MEMORY_LIMIT'] = '20480'  # 20GB per GPU\n",
    "os.environ['RAPIDS_NO_INITIALIZE'] = '1'\n",
    "\n",
    "# Temp directory configuration - use external drive\n",
    "os.environ['TMPDIR'] = '/media/knight2/EDB/tmp'\n",
    "os.environ['TEMP'] = '/media/knight2/EDB/tmp'\n",
    "os.environ['TMP'] = '/media/knight2/EDB/tmp'\n",
    "\n",
    "# Create temp directory\n",
    "import pathlib\n",
    "pathlib.Path('/media/knight2/EDB/tmp').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Environment configured for dual GPU processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Core libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "import gc\n",
    "\n",
    "# Add utils to path\n",
    "sys.path.append('/media/knight2/EDB/repos/Numer_crypto_v4/utils')\n",
    "sys.path.append('/media/knight2/EDB/repos/Numer_crypto_v4/scripts/data')\n",
    "sys.path.append('/media/knight2/EDB/repos/Numer_crypto_v4/scripts')\n",
    "print(\"üì¶ Core libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72e437a-332d-4b3b-ae54-67707a8564cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0dc44d-807f-4507-9192-e4477aaf7306",
   "metadata": {},
   "source": [
    "## Data Import en EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7958ce8b-be77-4a29-b25a-558697b34d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = 20250814"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877d74c3-6192-4da9-992f-82f6d01e492c",
   "metadata": {},
   "source": [
    "### Equity identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78f77497-c356-464e-a667-bca4db247f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = pl.read_csv('/media/knight2/EDB/numer_crypto_temp/data/raw/identifier/ticker_mapping_20250814.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "822b1392-ce0f-46c0-8688-a8cdf1163b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['numerai_ticker', 'yahoo_ticker']\n",
      "20734\n"
     ]
    }
   ],
   "source": [
    "print(company.columns)\n",
    "print(len(company['yahoo_ticker'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6a87a5-88e9-4433-9251-6702458374ca",
   "metadata": {},
   "source": [
    "### Equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01583b4-324f-44d2-a000-337cf0988807",
   "metadata": {},
   "outputs": [],
   "source": [
    "equity = pl.read_parquet(f'/media/knight2/EDB/numer_crypto_temp/data/raw/equity/equity_data_{today}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "593cb949-070d-4530-9a98-957d343fb8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'open', 'high', 'low', 'close', 'volume', 'dividends', 'stock splits', 'numerai_ticker', 'yahoo_ticker', 'capital gains']\n",
      "shape: (3,)\n",
      "Series: 'yahoo_ticker' [str]\n",
      "[\n",
      "\t\"TRNO\"\n",
      "\t\"LAZR\"\n",
      "\t\"Ayaly\"\n",
      "]\n",
      "12168\n"
     ]
    }
   ],
   "source": [
    "print(equity.columns)\n",
    "print(equity['yahoo_ticker'].unique().head(3))\n",
    "print(len(equity['yahoo_ticker'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ac98bd1-b455-41d5-bf80-8b8591651278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the unique values\n",
    "df = pl.DataFrame({\n",
    "    \"yahoo_ticker\": equity[\"yahoo_ticker\"].unique().to_list()\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.write_csv(f\"/media/knight2/EDB/numer_crypto_temp/data/result/equity_tickers_succes_{today}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5b1b47-e10d-43d8-9844-fd860fa928d3",
   "metadata": {},
   "source": [
    "### Crypto identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "485c4de5-5747-42ae-a621-8c10e6a59370",
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto = pl.read_csv('/media/knight2/EDB/numer_crypto_temp/data/raw/identifier/Cryptos_20250707.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3b2d3ac-fcf8-4ba2-b9b8-7bb2c710b696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['symbol', 'name', 'cryptos_train', 'cryptos_elig', 'coinmcap_rank_202507', 'platform', 'platform_symbol', 'prijs_vanaf', 'prijs_tot', 'in_all_currencie', 'data_ohlc_vanaf', 'data_ohlc_tot', 'volume_vanaf', 'volume_tot', 'uitstaand_vanaf', 'uitstaand_tot_202507', 'bron_uitstaand', 'api_rank', 'bron_historie', 'mcap_2025', 'top50', 'top_50_150_202507', 'top_150_250_202507', 'top_250_500_202507', 'top_500_750_202507', 'top_750_1000_202507', 'top_1000_1500_202507', 'top_1500_2000_202507', 'top_2000_10000_202507']\n",
      "1742\n"
     ]
    }
   ],
   "source": [
    "print(crypto.columns)\n",
    "print(len(crypto['symbol'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f942152c-2bb6-4e53-9a7b-af27dd42aaa0",
   "metadata": {},
   "source": [
    "### Crypto Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a1801f-3571-4a0d-ad37-917a65db0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = pl.read_parquet(f'/media/knight2/EDB/numer_crypto_temp/data/processed/price/crypto_numerai_all_symbols_live_train_cleaned_{today}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8449e170-0b31-4972-b17a-e83bd508d76d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['symbol', 'name', 'date', 'open', 'high', 'low', 'close', 'volume', 'marketcap', 'source']\n",
      "shape: (3,)\n",
      "Series: 'symbol' [str]\n",
      "[\n",
      "\t\"PIT\"\n",
      "\t\"CTT\"\n",
      "\t\"BHC\"\n",
      "]\n",
      "19\n",
      "shape: (19,)\n",
      "Series: 'source' [str]\n",
      "[\n",
      "\t\"binance\"\n",
      "\t\"kraken\"\n",
      "\t\"htx\"\n",
      "\t\"cryptocompare_api\"\n",
      "\t\"combined\"\n",
      "\t‚Ä¶\n",
      "\t\"bitfinex\"\n",
      "\t\"mobula\"\n",
      "\t\"dexscreener\"\n",
      "\t\"coinbase\"\n",
      "\t\"combined_sources\"\n",
      "]\n",
      "binance\n",
      "binance_api\n",
      "bitfinex\n",
      "bithumb\n",
      "bybit\n",
      "coinbase\n",
      "coingecko\n",
      "combined\n",
      "combined_sources\n",
      "cryptocompare\n",
      "cryptocompare_api\n",
      "dexscreener\n",
      "gate\n",
      "htx\n",
      "kaggle_unified_crypto_data\n",
      "kraken\n",
      "kucoin\n",
      "lbank\n",
      "mobula\n",
      "1739\n"
     ]
    }
   ],
   "source": [
    "print(price.columns)\n",
    "print(price['symbol'].unique().head(3))\n",
    "print(len(price['source'].unique()))\n",
    "print(price['source'].unique())\n",
    "sources = price['source'].unique().sort().to_list()\n",
    "for s in sources:\n",
    "    print(s)\n",
    "print(len(price['symbol'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c1dc04-1cb9-46a4-b1bf-a00d17d0ebad",
   "metadata": {},
   "source": [
    "### Equity feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc1a5f6-464a-4d86-87ac-093273db370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossasset = pl.read_parquet(f'/media/knight2/EDB/numer_crypto_temp/data/processed/equity/selection/equity_selection_{today}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed3b8b-854a-46bd-b549-e2287369096a",
   "metadata": {},
   "source": [
    "### Cross (crypto) asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4f3f3-2ac6-4076-bb1f-4118efed6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossasset = pl.read_parquet(f'')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d947e3b1-fbb2-40e4-98a6-d53343e4874b",
   "metadata": {},
   "source": [
    "### Yiedl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ed5150-89e8-4638-ab3e-967d8b3432cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_round = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779dd5fd-56ed-4993-9d15-c705dbc413e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yiedl = pl.read_parquet(f'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "model-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ H2O Sparkling Water available\n",
      "‚úÖ AutoGluon TimeSeries available\n",
      "‚úÖ LightGBM available\n",
      "‚úÖ Feature generators available\n",
      "‚úÖ Feature generators available\n",
      "\n",
      "üìä Available models: ['H2O', 'AutoGluonTS', 'LightGBM']\n"
     ]
    }
   ],
   "source": [
    "# Model-specific imports\n",
    "model_status = {}\n",
    "\n",
    "# H2O Sparkling Water\n",
    "try:\n",
    "    import h2o\n",
    "    from h2o.automl import H2OAutoML\n",
    "    model_status['H2O'] = True\n",
    "    print(\"‚úÖ H2O Sparkling Water available\")\n",
    "except ImportError:\n",
    "    model_status['H2O'] = False\n",
    "    print(\"‚ö†Ô∏è H2O not available\")\n",
    "\n",
    "# AutoGluon TimeSeries\n",
    "try:\n",
    "    from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "    model_status['AutoGluonTS'] = True\n",
    "    print(\"‚úÖ AutoGluon TimeSeries available\")\n",
    "except ImportError:\n",
    "    model_status['AutoGluonTS'] = False\n",
    "    print(\"‚ö†Ô∏è AutoGluon TimeSeries not available\")\n",
    "\n",
    "# SynapseML LightGBM\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    model_status['LightGBM'] = True\n",
    "    print(\"‚úÖ LightGBM available\")\n",
    "except ImportError:\n",
    "    model_status['LightGBM'] = False\n",
    "    print(\"‚ö†Ô∏è LightGBM not available\")\n",
    "\n",
    "# Data loading utilities\n",
    "try:\n",
    "    from data_preparation import ComprehensiveDataPreparation #ModularDataPreparation\n",
    "    print(\"‚úÖ Feature generators available\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Feature generators not available\")\n",
    "# Data loading utilities\n",
    "try:\n",
    "    from real_data_features import RealDataFeatureGenerator\n",
    "    print(\"‚úÖ Feature generators available\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Feature generators not available\")\n",
    "\n",
    "print(f\"\\nüìä Available models: {[k for k, v in model_status.items() if v]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "configuration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Configuration initialized - Run ID: crypto_pipeline_20250814_160231\n",
      "üìÅ Submission dir: /media/knight2/EDB/numer_crypto_temp/data/submission\n",
      "üíæ Model dir: /media/knight2/EDB/numer_crypto_temp/data/model\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        # Directories\n",
    "        self.base_dir = Path(\"/media/knight2/EDB/numer_crypto_temp/data\")\n",
    "        self.submission_dir = self.base_dir / \"submission\"\n",
    "        self.model_dir = self.base_dir / \"model\"\n",
    "        self.repo_models_dir = Path(\"/media/knight2/EDB/repos/Numer_crypto_v4/models\")\n",
    "        \n",
    "        # Create directories\n",
    "        for dir_path in [self.submission_dir, self.model_dir, self.repo_models_dir]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Performance targets\n",
    "        self.target_rmse = 0.19\n",
    "        self.target_corr = 0.50\n",
    "        self.target_mmc = 0.20\n",
    "        \n",
    "        # Model configurations\n",
    "        self.model_configs = {\n",
    "            'H2O': {'time_limit': 1800},  # 30 minutes\n",
    "            'AutoGluonTS': {'time_limit': 1800},\n",
    "            'LightGBM': {'time_limit': 1200}  # 20 minutes\n",
    "        }\n",
    "\n",
    "config = Config()\n",
    "print(f\"‚öôÔ∏è Configuration initialized - Run ID: crypto_pipeline_{config.timestamp}\")\n",
    "print(f\"üìÅ Submission dir: {config.submission_dir}\")\n",
    "print(f\"üíæ Model dir: {config.model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "logging-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:02:31,613 - INFO - üèÜ Starting Crypto Pipeline V4 Notebook\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Logging to: /media/knight2/EDB/numer_crypto_temp/data/logs/crypto_pipeline_notebook_20250814_160231.log\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "log_file = config.base_dir / \"logs\" / f\"crypto_pipeline_notebook_{config.timestamp}.log\"\n",
    "log_file.parent.mkdir(exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"üèÜ Starting Crypto Pipeline V4 Notebook\")\n",
    "print(f\"üìù Logging to: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-title",
   "metadata": {},
   "source": [
    "## üìä Data Loading and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf89c22-b361-45b0-a600-f3f59f860c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Optional\n",
    "def load_real_data() -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Load real historical price data\"\"\"\n",
    "    print(\"üìä Loading real historical price data...\")\n",
    "    \n",
    "    try:\n",
    "        # Try primary parquet files first\n",
    "        price_dir = \"media/knight2/EDB/numer_crypto_temp/data/raw/price\" #self.temp_dir / \n",
    "        parquet_files = list(price_dir.glob(\"*.parquet\"))\n",
    "        \n",
    "        if parquet_files:\n",
    "            price_df = pd.read_parquet(parquet_files[0])\n",
    "            price_df['date'] = pd.to_datetime(price_df['date'])\n",
    "            print(f\"‚úÖ Loaded {len(price_df):,} price records from parquet\")\n",
    "            return price_df\n",
    "        \n",
    "        # Fallback to CSV files\n",
    "        csv_dir =  \"/media/knight2/EDB/numer_crypto_temp/data/price/output\" #self.temp_dir /\n",
    "        if csv_dir.exists():\n",
    "            csv_files = list(csv_dir.glob(\"*_historical.csv\"))\n",
    "            all_data = []\n",
    "            \n",
    "            for csv_file in csv_files:\n",
    "                try:\n",
    "                    df = pd.read_csv(csv_file)\n",
    "                    if len(df) > 10000:  # Only cryptos with sufficient data\n",
    "                        all_data.append(df)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            if all_data:\n",
    "                combined_df = pd.concat(all_data, ignore_index=True)\n",
    "                combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
    "                print(f\"‚úÖ Loaded {len(combined_df):,} CSV records\")\n",
    "                return combined_df\n",
    "\n",
    "        # Prepare features and target\n",
    "        feature_cols = [col for col in combined_df.columns if col not in ['symbol', 'target']]\n",
    "        X = combined_df[['symbol'] + feature_cols]\n",
    "        y = combined_df['target']\n",
    "        \n",
    "        # Remove any remaining NaN values\n",
    "        mask = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "        X = X[mask].reset_index(drop=True)\n",
    "        y = y[mask].reset_index(drop=True)\n",
    "        \n",
    "        load_time = time.time() - start_time\n",
    "        logger.info(f\"‚úÖ Data loaded: {X.shape[0]} samples, {len(feature_cols)} features\")\n",
    "        logger.info(f\"‚è±Ô∏è Load time: {load_time:.1f} seconds\")\n",
    "        \n",
    "        return X, y\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load price data: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "load-real-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading real historical price data...\n",
      "‚ùå Failed to load price data: 'str' object has no attribute 'glob'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mdef load_real_data():\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    \"\"\"Load real data with comprehensive feature engineering\"\"\"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m \u001b[33;03m        return None, None\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m X, y = load_real_data()\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     42\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìà Data Summary:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def load_real_data():\n",
    "    \"\"\"Load real data with comprehensive feature engineering\"\"\"\n",
    "    logger.info(\"üìä Loading real data with comprehensive features...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Initialize feature generator\n",
    "        feature_gen = RealDataFeatureGenerator()\n",
    "        \n",
    "        # Load comprehensive features\n",
    "        df = feature_gen.generate_all_real_features()#generate_comprehensive_features()\n",
    "        \n",
    "        if df.empty:\n",
    "            logger.error(\"‚ùå No data loaded from RealDataFeatureGenerator\")\n",
    "            return None, None\n",
    "        \n",
    "        # Prepare features and target\n",
    "        feature_cols = [col for col in df.columns if col not in ['symbol', 'target']]\n",
    "        X = df[['symbol'] + feature_cols]\n",
    "        y = df['target']\n",
    "        \n",
    "        # Remove any remaining NaN values\n",
    "        mask = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "        X = X[mask].reset_index(drop=True)\n",
    "        y = y[mask].reset_index(drop=True)\n",
    "        \n",
    "        load_time = time.time() - start_time\n",
    "        logger.info(f\"‚úÖ Data loaded: {X.shape[0]} samples, {len(feature_cols)} features\")\n",
    "        logger.info(f\"‚è±Ô∏è Load time: {load_time:.1f} seconds\")\n",
    "        \n",
    "        return X, y\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Data loading failed: {e}\")\n",
    "        return None, None\n",
    "'''\n",
    "# Load the data\n",
    "X, y = load_real_data()\n",
    "\n",
    "if X is not None and y is not None:\n",
    "    print(f\"\\nüìà Data Summary:\")\n",
    "    print(f\"   Samples: {len(X):,}\")\n",
    "    print(f\"   Features: {len([col for col in X.columns if col != 'symbol']):,}\")\n",
    "    print(f\"   Symbols: {X['symbol'].nunique():,}\")\n",
    "    print(f\"   Target range: {y.min():.4f} to {y.max():.4f}\")\n",
    "    print(f\"   Target mean: {y.mean():.4f} ¬± {y.std():.4f}\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to load data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "data-split",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Prepare data for training\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mX\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Prepare features and split data\u001b[39;00m\n\u001b[32m      4\u001b[39m     feature_cols = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m X.columns \u001b[38;5;28;01mif\u001b[39;00m col != \u001b[33m'\u001b[39m\u001b[33msymbol\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m     X_features = X[feature_cols]\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "if X is not None and y is not None:\n",
    "    # Prepare features and split data\n",
    "    feature_cols = [col for col in X.columns if col != 'symbol']\n",
    "    X_features = X[feature_cols]\n",
    "    symbols = X['symbol'].values\n",
    "    \n",
    "    # Train/test split with time series considerations\n",
    "    X_train, X_test, y_train, y_test, symbols_train, symbols_test = train_test_split(\n",
    "        X_features, y, symbols, test_size=0.3, random_state=42, shuffle=False\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"‚úÖ Data split: Train={len(X_train)}, Test={len(X_test)}, Features={len(feature_cols)}\")\n",
    "    \n",
    "    print(f\"\\nüîÑ Data Split Summary:\")\n",
    "    print(f\"   Training samples: {len(X_train):,}\")\n",
    "    print(f\"   Testing samples: {len(X_test):,}\")\n",
    "    print(f\"   Features: {len(feature_cols):,}\")\n",
    "    \n",
    "    # Display feature statistics\n",
    "    print(f\"\\nüìä Feature Statistics:\")\n",
    "    print(f\"   Training target mean: {y_train.mean():.4f} ¬± {y_train.std():.4f}\")\n",
    "    print(f\"   Testing target mean: {y_test.mean():.4f} ¬± {y_test.std():.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot proceed without data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-training-title",
   "metadata": {},
   "source": [
    "## ü§ñ Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def calculate_performance_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate comprehensive performance metrics\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    correlation = spearmanr(y_true, y_pred)[0]\n",
    "    \n",
    "    # MMC estimation (simplified)\n",
    "    mmc = np.corrcoef(y_true - y_true.mean(), y_pred - y_pred.mean())[0, 1] * 2 - 1\n",
    "    mmc = max(-1, min(1, mmc))  # Clamp to [-1, 1]\n",
    "    \n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "        'correlation': correlation,\n",
    "        'mmc_estimate': mmc\n",
    "    }\n",
    "\n",
    "def check_performance_targets(metrics):\n",
    "    \"\"\"Check if performance meets targets\"\"\"\n",
    "    return {\n",
    "        'meets_targets': (\n",
    "            metrics['rmse'] < config.target_rmse and\n",
    "            metrics['correlation'] > config.target_corr and\n",
    "            metrics['mmc_estimate'] > config.target_mmc\n",
    "        ),\n",
    "        'rmse_target': metrics['rmse'] < config.target_rmse,\n",
    "        'corr_target': metrics['correlation'] > config.target_corr,\n",
    "        'mmc_target': metrics['mmc_estimate'] > config.target_mmc\n",
    "    }\n",
    "\n",
    "def create_submission_file(predictions, symbols, model_name, metadata):\n",
    "    \"\"\"Create Numerai submission file\"\"\"\n",
    "    submission_df = pd.DataFrame({\n",
    "        'symbol': symbols,\n",
    "        'signal': np.clip(predictions, 0.001, 0.999)  # Clip to valid range\n",
    "    })\n",
    "    \n",
    "    submission_filename = f\"{model_name.lower()}_submission_{config.timestamp}.csv\"\n",
    "    submission_path = config.submission_dir / submission_filename\n",
    "    \n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata_filename = f\"{model_name.lower()}_metadata_{config.timestamp}.json\"\n",
    "    metadata_path = config.submission_dir / metadata_filename\n",
    "    \n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2, default=str)\n",
    "    \n",
    "    return submission_path, metadata_path\n",
    "\n",
    "print(\"üîß Utility functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h2o-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2O AutoML Training\n",
    "def train_h2o_model():\n",
    "    \"\"\"Train H2O AutoML model\"\"\"\n",
    "    if not model_status['H2O']:\n",
    "        logger.warning(\"‚ö†Ô∏è H2O not available, skipping\")\n",
    "        return None, None, None\n",
    "    \n",
    "    logger.info(\"üíß Training H2O Sparkling Water AutoML...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Initialize H2O\n",
    "        h2o.init(nthreads=-1, max_mem_size=\"40G\", strict_version_check=False)\n",
    "        \n",
    "        # Prepare data\n",
    "        train_data = pd.concat([X_train, pd.Series(y_train, name='target')], axis=1)\n",
    "        test_data = pd.concat([X_test, pd.Series(y_test, name='target')], axis=1)\n",
    "        \n",
    "        # Convert to H2O frames\n",
    "        h2o_train = h2o.H2OFrame(train_data)\n",
    "        h2o_test = h2o.H2OFrame(test_data)\n",
    "        \n",
    "        # Set target and features\n",
    "        target = 'target'\n",
    "        features = [col for col in h2o_train.columns if col != target]\n",
    "        \n",
    "        # Train AutoML\n",
    "        aml = H2OAutoML(\n",
    "            max_runtime_secs=config.model_configs['H2O']['time_limit'],\n",
    "            seed=42,\n",
    "            sort_metric='RMSE',\n",
    "            exclude_algos=['DeepLearning'],  # Focus on faster algorithms\n",
    "            max_models=20\n",
    "        )\n",
    "        \n",
    "        aml.train(x=features, y=target, training_frame=h2o_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions_h2o = aml.predict(h2o_test)\n",
    "        y_pred_test = predictions_h2o.as_data_frame()['predict'].values\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_performance_metrics(y_test, y_pred_test)\n",
    "        targets_check = check_performance_targets(metrics)\n",
    "        \n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        metadata = {\n",
    "            'model_name': 'H2O',\n",
    "            'test_rmse': float(metrics['rmse']),\n",
    "            'test_correlation': float(metrics['correlation']),\n",
    "            'mmc_estimate': float(metrics['mmc_estimate']),\n",
    "            'train_time': train_time,\n",
    "            'meets_targets': targets_check['meets_targets'],\n",
    "            'best_model': str(aml.leader)\n",
    "        }\n",
    "        \n",
    "        status = \"‚úÖ PASS\" if targets_check['meets_targets'] else \"‚ö†Ô∏è PARTIAL\"\n",
    "        logger.info(f\"   {status} H2O: RMSE={metrics['rmse']:.4f}, Corr={metrics['correlation']:.4f}, MMC‚âà{metrics['mmc_estimate']:.4f}, Time={train_time:.1f}s\")\n",
    "        \n",
    "        return aml, metadata, y_pred_test\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå H2O training failed: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Train H2O model if available\n",
    "if model_status['H2O'] and X is not None:\n",
    "    h2o_model, h2o_metadata, h2o_predictions = train_h2o_model()\n",
    "    \n",
    "    if h2o_model is not None:\n",
    "        # Create submission file\n",
    "        submission_path, metadata_path = create_submission_file(\n",
    "            h2o_predictions, symbols_test, 'H2O', h2o_metadata\n",
    "        )\n",
    "        print(f\"üìÑ H2O submission: {submission_path.name}\")\n",
    "    else:\n",
    "        print(\"‚ùå H2O training failed\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è H2O training skipped\")\n",
    "    h2o_model, h2o_metadata, h2o_predictions = None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "autogluon-ts-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoGluon TimeSeries Training\n",
    "def train_autogluon_timeseries():\n",
    "    \"\"\"Train AutoGluon TimeSeries model\"\"\"\n",
    "    if not model_status['AutoGluonTS']:\n",
    "        logger.warning(\"‚ö†Ô∏è AutoGluon TimeSeries not available, skipping\")\n",
    "        return None, None, None\n",
    "    \n",
    "    logger.info(\"üìà Training AutoGluon TimeSeriesPredictor...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Prepare time series data (limited sample for efficiency)\n",
    "        max_samples = min(10000, len(y_train))\n",
    "        sample_indices = np.linspace(0, len(y_train)-1, max_samples, dtype=int)\n",
    "        \n",
    "        # Create time series dataframe\n",
    "        ts_data = []\n",
    "        for i, idx in enumerate(sample_indices):\n",
    "            ts_data.append({\n",
    "                'item_id': f'crypto_{i}',\n",
    "                'timestamp': pd.Timestamp('2020-01-01') + pd.Timedelta(days=i),\n",
    "                'target': y_train.iloc[idx]\n",
    "            })\n",
    "        \n",
    "        train_ts = TimeSeriesDataFrame.from_data_frame(\n",
    "            pd.DataFrame(ts_data),\n",
    "            id_column='item_id',\n",
    "            timestamp_column='timestamp'\n",
    "        )\n",
    "        \n",
    "        # TimeSeries predictor\n",
    "        ts_path = f'/media/knight2/EDB/tmp/autogluon_ts_{config.timestamp}'\n",
    "        prediction_length = min(30, len(y_test))\n",
    "        \n",
    "        predictor = TimeSeriesPredictor(\n",
    "            target='target',\n",
    "            prediction_length=prediction_length,\n",
    "            path=ts_path,\n",
    "            eval_metric='RMSE',\n",
    "            verbosity=1\n",
    "        )\n",
    "        \n",
    "        # Train with optimized hyperparameters\n",
    "        ts_hyperparameters = {\n",
    "            \"Naive\": {},\n",
    "            \"SeasonalNaive\": {},\n",
    "            \"ARIMA\": {'maxiter': 50},\n",
    "            \"ETS\": {'maxiter': 100},\n",
    "            \"Theta\": {},\n",
    "        }\n",
    "        \n",
    "        predictor.fit(\n",
    "            train_ts,\n",
    "            time_limit=config.model_configs['AutoGluonTS']['time_limit'],\n",
    "            presets='best_quality',\n",
    "            hyperparameters=ts_hyperparameters\n",
    "        )\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = predictor.predict(train_ts)\n",
    "        y_pred_test = predictions['mean'].values[:len(y_test)]\n",
    "        \n",
    "        # Pad with mean if needed\n",
    "        if len(y_pred_test) < len(y_test):\n",
    "            mean_pred = np.mean(y_pred_test)\n",
    "            padding = np.full(len(y_test) - len(y_pred_test), mean_pred)\n",
    "            y_pred_test = np.concatenate([y_pred_test, padding])\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_performance_metrics(y_test, y_pred_test)\n",
    "        targets_check = check_performance_targets(metrics)\n",
    "        \n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        metadata = {\n",
    "            'model_name': 'AutoGluonTS',\n",
    "            'test_rmse': float(metrics['rmse']),\n",
    "            'test_correlation': float(metrics['correlation']),\n",
    "            'mmc_estimate': float(metrics['mmc_estimate']),\n",
    "            'train_time': train_time,\n",
    "            'meets_targets': targets_check['meets_targets'],\n",
    "            'prediction_length': prediction_length\n",
    "        }\n",
    "        \n",
    "        status = \"‚úÖ PASS\" if targets_check['meets_targets'] else \"‚ö†Ô∏è PARTIAL\"\n",
    "        logger.info(f\"   {status} AutoGluon TS: RMSE={metrics['rmse']:.4f}, Corr={metrics['correlation']:.4f}, MMC‚âà{metrics['mmc_estimate']:.4f}, Time={train_time:.1f}s\")\n",
    "        \n",
    "        return predictor, metadata, y_pred_test\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå AutoGluon TS training failed: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Train AutoGluon TS model if available\n",
    "if model_status['AutoGluonTS'] and X is not None:\n",
    "    agts_model, agts_metadata, agts_predictions = train_autogluon_timeseries()\n",
    "    \n",
    "    if agts_model is not None:\n",
    "        # Create submission file\n",
    "        submission_path, metadata_path = create_submission_file(\n",
    "            agts_predictions, symbols_test, 'AutoGluonTS', agts_metadata\n",
    "        )\n",
    "        print(f\"üìÑ AutoGluon TS submission: {submission_path.name}\")\n",
    "    else:\n",
    "        print(\"‚ùå AutoGluon TS training failed\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è AutoGluon TS training skipped\")\n",
    "    agts_model, agts_metadata, agts_predictions = None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightgbm-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SynapseML LightGBM Training\n",
    "def train_lightgbm_model():\n",
    "    \"\"\"Train SynapseML LightGBM model with advanced hyperparameters\"\"\"\n",
    "    if not model_status['LightGBM']:\n",
    "        logger.warning(\"‚ö†Ô∏è LightGBM not available, skipping\")\n",
    "        return None, None, None\n",
    "    \n",
    "    logger.info(\"üî• Training SynapseML LightGBM with advanced hyperparameters...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Advanced LightGBM parameters optimized for crypto prediction\n",
    "        lgb_params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 127,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'min_child_samples': 20,\n",
    "            'min_child_weight': 0.001,\n",
    "            'reg_alpha': 0.1,\n",
    "            'reg_lambda': 0.1,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'verbose': -1,\n",
    "            'device_type': 'gpu',  # SynapseML GPU acceleration\n",
    "            'gpu_platform_id': 0,\n",
    "            'gpu_device_id': 0,\n",
    "            'max_bin': 255,\n",
    "            'min_data_in_bin': 3,\n",
    "            'path_smooth': 0.1\n",
    "        }\n",
    "        \n",
    "        # Prepare datasets\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "        \n",
    "        # Train model with early stopping\n",
    "        model = lgb.train(\n",
    "            lgb_params,\n",
    "            train_data,\n",
    "            num_boost_round=2000,\n",
    "            valid_sets=[train_data, val_data],\n",
    "            valid_names=['train', 'eval'],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=100\n",
    "        )\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_test = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_performance_metrics(y_test, y_pred_test)\n",
    "        targets_check = check_performance_targets(metrics)\n",
    "        \n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Feature importance\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': feature_cols,\n",
    "            'importance': model.feature_importance()\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        metadata = {\n",
    "            'model_name': 'LightGBM',\n",
    "            'test_rmse': float(metrics['rmse']),\n",
    "            'test_correlation': float(metrics['correlation']),\n",
    "            'mmc_estimate': float(metrics['mmc_estimate']),\n",
    "            'train_time': train_time,\n",
    "            'meets_targets': targets_check['meets_targets'],\n",
    "            'best_iteration': int(model.best_iteration),\n",
    "            'num_features': len(feature_cols),\n",
    "            'top_features': feature_importance.head(10)['feature'].tolist()\n",
    "        }\n",
    "        \n",
    "        # Save model\n",
    "        model_filename = f\"lightgbm_model_{config.timestamp}.pkl\"\n",
    "        model_path = config.model_dir / model_filename\n",
    "        model_path_repo = config.repo_models_dir / model_filename\n",
    "        \n",
    "        joblib.dump(model, model_path)\n",
    "        joblib.dump(model, model_path_repo)\n",
    "        \n",
    "        status = \"‚úÖ PASS\" if targets_check['meets_targets'] else \"‚ö†Ô∏è PARTIAL\"\n",
    "        logger.info(f\"   {status} LightGBM: RMSE={metrics['rmse']:.4f}, Corr={metrics['correlation']:.4f}, MMC‚âà{metrics['mmc_estimate']:.4f}, Time={train_time:.1f}s\")\n",
    "        logger.info(f\"   üíæ Model saved: {model_filename}\")\n",
    "        \n",
    "        return model, metadata, y_pred_test\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå LightGBM training failed: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Train LightGBM model if available\n",
    "if model_status['LightGBM'] and X is not None:\n",
    "    lgb_model, lgb_metadata, lgb_predictions = train_lightgbm_model()\n",
    "    \n",
    "    if lgb_model is not None:\n",
    "        # Create submission file\n",
    "        submission_path, metadata_path = create_submission_file(\n",
    "            lgb_predictions, symbols_test, 'LightGBM', lgb_metadata\n",
    "        )\n",
    "        print(f\"üìÑ LightGBM submission: {submission_path.name}\")\n",
    "    else:\n",
    "        print(\"‚ùå LightGBM training failed\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è LightGBM training skipped\")\n",
    "    lgb_model, lgb_metadata, lgb_predictions = None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-title",
   "metadata": {},
   "source": [
    "## üìä Results Summary and Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results\n",
    "all_results = {}\n",
    "all_predictions = []\n",
    "successful_models = []\n",
    "\n",
    "# Add H2O results\n",
    "if h2o_model is not None and h2o_predictions is not None:\n",
    "    all_results['H2O'] = h2o_metadata\n",
    "    all_predictions.append(h2o_predictions)\n",
    "    successful_models.append('H2O')\n",
    "\n",
    "# Add AutoGluon TS results\n",
    "if agts_model is not None and agts_predictions is not None:\n",
    "    all_results['AutoGluonTS'] = agts_metadata\n",
    "    all_predictions.append(agts_predictions)\n",
    "    successful_models.append('AutoGluonTS')\n",
    "\n",
    "# Add LightGBM results\n",
    "if lgb_model is not None and lgb_predictions is not None:\n",
    "    all_results['LightGBM'] = lgb_metadata\n",
    "    all_predictions.append(lgb_predictions)\n",
    "    successful_models.append('LightGBM')\n",
    "\n",
    "print(f\"\\nüéØ RESULTS SUMMARY:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if all_results:\n",
    "    for model_name, metadata in all_results.items():\n",
    "        status = \"‚úÖ PASS\" if metadata['meets_targets'] else \"‚ö†Ô∏è PARTIAL\"\n",
    "        print(f\"{status} {model_name}:\")\n",
    "        print(f\"   RMSE: {metadata['test_rmse']:.4f} (target: <{config.target_rmse})\")\n",
    "        print(f\"   Correlation: {metadata['test_correlation']:.4f} (target: >{config.target_corr})\")\n",
    "        print(f\"   MMC: {metadata['mmc_estimate']:.4f} (target: >{config.target_mmc})\")\n",
    "        print(f\"   Training Time: {metadata['train_time']:.1f}s\")\n",
    "        print()\n",
    "    \n",
    "    # Performance summary\n",
    "    best_rmse = min([r['test_rmse'] for r in all_results.values()])\n",
    "    best_corr = max([r['test_correlation'] for r in all_results.values()])\n",
    "    best_mmc = max([r['mmc_estimate'] for r in all_results.values()])\n",
    "    \n",
    "    print(f\"üèÜ BEST PERFORMANCE:\")\n",
    "    print(f\"   Best RMSE: {best_rmse:.4f}\")\n",
    "    print(f\"   Best Correlation: {best_corr:.4f}\")\n",
    "    print(f\"   Best MMC: {best_mmc:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No successful models to report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble if multiple models are available\n",
    "if len(all_predictions) > 1:\n",
    "    logger.info(f\"üé≠ Creating ensemble from {len(all_predictions)} models...\")\n",
    "    \n",
    "    # Simple average ensemble\n",
    "    ensemble_predictions = np.mean(all_predictions, axis=0)\n",
    "    \n",
    "    # Calculate ensemble metrics\n",
    "    ensemble_metrics = calculate_performance_metrics(y_test, ensemble_predictions)\n",
    "    ensemble_targets = check_performance_targets(ensemble_metrics)\n",
    "    \n",
    "    # Create ensemble metadata\n",
    "    ensemble_metadata = {\n",
    "        'model_name': 'Ensemble',\n",
    "        'test_rmse': float(ensemble_metrics['rmse']),\n",
    "        'test_correlation': float(ensemble_metrics['correlation']),\n",
    "        'mmc_estimate': float(ensemble_metrics['mmc_estimate']),\n",
    "        'meets_targets': ensemble_targets['meets_targets'],\n",
    "        'component_models': successful_models,\n",
    "        'ensemble_method': 'simple_average'\n",
    "    }\n",
    "    \n",
    "    # Create ensemble submission\n",
    "    submission_path, metadata_path = create_submission_file(\n",
    "        ensemble_predictions, symbols_test, 'Ensemble', ensemble_metadata\n",
    "    )\n",
    "    \n",
    "    status = \"‚úÖ PASS\" if ensemble_targets['meets_targets'] else \"‚ö†Ô∏è PARTIAL\"\n",
    "    print(f\"\\n{status} ENSEMBLE ({len(successful_models)} models):\")\n",
    "    print(f\"   RMSE: {ensemble_metrics['rmse']:.4f}\")\n",
    "    print(f\"   Correlation: {ensemble_metrics['correlation']:.4f}\")\n",
    "    print(f\"   MMC: {ensemble_metrics['mmc_estimate']:.4f}\")\n",
    "    print(f\"   üìÑ Ensemble submission: {submission_path.name}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Ensemble not created (need 2+ models)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(f\"\\nüéâ CRYPTO PIPELINE V4 COMPLETED!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Successful Models: {len(successful_models)}/{len(model_status)}\")\n",
    "print(f\"üèÜ Models: {', '.join(successful_models) if successful_models else 'None'}\")\n",
    "print(f\"üìÅ Submission Directory: {config.submission_dir}\")\n",
    "print(f\"üíæ Model Directory: {config.model_dir}\")\n",
    "print(f\"üìù Log File: {log_file}\")\n",
    "\n",
    "if successful_models:\n",
    "    # List all generated files\n",
    "    submission_files = list(config.submission_dir.glob(f\"*_{config.timestamp}.csv\"))\n",
    "    print(f\"\\nüìÑ Generated Submission Files:\")\n",
    "    for file in submission_files:\n",
    "        print(f\"   ‚Ä¢ {file.name}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Pipeline completed successfully!\")\n",
    "    print(f\"   Ready for Numerai submission: {len(submission_files)} files\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Pipeline failed - no successful models\")\n",
    "\n",
    "logger.info(f\"üèÜ Crypto Pipeline V4 notebook completed - {len(successful_models)} successful models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numer_crypto_temp",
   "language": "python",
   "name": "numer_crypto_temp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
